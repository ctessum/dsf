## Distributed Science Framework

Here we propose a candidate framework for meeting the design constraints above, the Distributed Science Framework (DSF).
The candidate framework acts both as a publisher and a funder of science.
At its core is the concept of Liberal Radicalism (LR; Buterin et al., 2018), a system for the efficient allocation of grant funding.
The key components are users, credits, articles, reviews, and grants.

### Components

#### Users

DSF users are online entities that are verified to be individual humans.
Verification is critical to avoid the gaming of the system, and will be accomplished by requiring each user to have an email address issued by an institution that is registered with DSF.

#### Credits

DSF credits are a digital currency system that can be converted to and from dollars or other global currencies.
Credits are used to distribute grants and review compensation and to pay for article uploads and downloads.

#### Articles

Articles are scientific manuscripts, equivalent to articles in existing scientific journals.
Authors pay a fee to upload a manuscript, which is published immediately.
Authors must provide contribution percents for each author (adding up to 100% for all authors) upon uploading an article.
Articles are only available to users; this could be enforced using DRM or blockchain technology, or using weaker methods currently favored by traditional publishers.
A new user gets one article download for free, subsequent articles must be paid for using credits.
The credits required to download an article will be approximately equivalent to the credits given for reviewing an article, so users not able or wishing to pay for articles with money can pay for a new article by submitting a review of their previous download.

#### Reviews and metareviews

Users can submit reviews of articles they have read both using quantitative rubrics and text responses, similar to existing journals.
Unlike existing journals, reviewers would be compensated using credits.
Users will also receive compensation for submitting metareviews (reviews of reviews).

#### Grants

Agencies and individuals who wish to provide financial funds for science can register grants through DSF.
Funders can specify criteria that users must meet to be eligible for a grant (including topics of previous articles, location, etc.) and restrictions regarding what the grant money can be spent on.
Then, grant funds will be allocated among qualified users based on the quality of their previous articles.

Article quality will be determined by an algorithm that includes number of unique users that have downloaded the article, citations, and reviews.
Review scores will be weighted by results of metareviews and by the quality scores of articles authored by the reviewer.

Funds would be allocated among multiple authors of a paper according to percent contribution values submitted when the article was uploaded.

It is worth noting that this system of grant funding inherently makes decisions on the merits of past contributions rather than ideas for future work.
This gives funders less control over which projects are funded than is customary with traditional funding mechanisms, but also creates opportunities for philanthropic individuals and organizations that want to "give back" but do not have the expertise to determine which projects would be useful.
This system also would remove the burden associated with preparing grant proposals, and reduce the barrier to participation associated with the common practice of using funding from a previous grant to generate "preliminary results" for use in applying for a future grant.

#### Operational overhead and revenue model

DSF would need to be implemented and operated by an organization.
Functions of the organization would include creating and maintaining the DSF software infrastructure, moderating user content, and policing for abuse of the system.

These activities could be funded by grant overhead.
As machine learning and artificial intelligence technology improves over time, AI could potentially be used to synthesize information contained in the articles and reviews into revenue-generating products (for example, automatic literature reviews) that could provide operating revenue and additional compensation for authors and reviewers.

### How DSF meets the design constraints

* __Sort, don't filter__: Articles are published immediately, but ranked according to reviews and metareviews. DSF will include searching and sorting algorithms the prioritize the return of high-quality articles.
* __Distributed, compensated review__: Users will be paid for reviews, and financially-constrained users can submit reviews in lieu of paying for article downloads and uploads
* __Minimize barriers to access to and participation in science__: Downloading and publishing articles can be paid for by submitting reviews
* __Distribute funding decisions__: Grants are distributed algorithmically based downloads and a distributed review system.
* __Preserve data ownership__: Users are compensated for reviews and for publishing high-quality articles.
* __Break network effects__: Early adopters be incentivised to participate by the relatively easy access to grant funding. As the number of users increases, the competition for grant funding will increase, as will the prestige associated with having a highly-rated article.

### Core assumptions

Here we list some core assumptions built into the design of DSF:

1. Users can be verifiably matched to individual humans: The success of any liberal radical approach relies on successfully mapping system users to individual humans (Buterin et al, 2018).
If one human can act as many users, then a distributed system is in danger of becoming a centralized one, centered around that individual.
DSF will initially use email identities issued by reputable institutions to perform this verification.

2. Users can be prevented from colluding to affect outcomes: The system could also be subverted by users colluding the boost rating of an article by flooding it with positive reviews and downloads or by creating a citation network among many low quality articles. This type of collusion may not be completely avoidable, but we expect that a combination of automated and human moderation and strict user verification can minimize the damage caused by collusion.

3. It is possible to build an algorithm that ranks article quality in a way consistent with traditional considerations of article scientific rigor, novelty, etc, and that authors will trust it to rate their work: We expect that because the algorithm will rely heavily on quantitative reviews from human users, and because the review scores will be weighted in part based on traditional metrics such as the number citations accumulated by a reviewer's articles, that the system will be familiar and transparent enough to be adopted.

4. Funders will be amenable to giving up control of the projects they fund: This may be objectionable to some funders, but it also may remove barriers to participation by other funders.

5. Monetary incentives for publication will be enough to overcome network affects associated with current funding and publication systems: This seems plausible given that money is known to be a strong motivator.
